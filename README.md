Tokenize-It
===========

Tokenize-it is a research project aimed to develop effective text tokenization approach robust against missed separation tokens like spaces and punctuation marks.

Dependencies
------------

- NumPy
- Matplotlib
- Pandas
- Seaborn
